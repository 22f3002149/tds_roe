{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f31f47",
   "metadata": {},
   "source": [
    "Note: The franchisee question is similar to the concept of convex hull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c3c0de",
   "metadata": {},
   "source": [
    "Convert HTML to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc3f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uvx markitdown $FILE.pdf > markitdown.md\n",
    "# run the above command in BASH Terminal to convert the HTML or PDF file to markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ad6b4",
   "metadata": {},
   "source": [
    "Simple distance shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a67bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83db561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Ritwik\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Istanbul, Doha, Dubai, Mumbai, Colombo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Ritwik\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl\n",
    "flight_connections = pd.read_excel('excel_tables.xlsx', sheet_name='Table 4')\n",
    "cities = pd.read_excel('excel_tables.xlsx', sheet_name='Table 5')\n",
    "%pip install networkx\n",
    "import networkx as nx\n",
    "G = nx.from_pandas_edgelist(flight_connections, source='From', target='To')\n",
    "shortest_path = nx.shortest_path(G, source='Istanbul', target='Colombo', weight='Distance')\n",
    "formatted_path = ', '.join(shortest_path)\n",
    "print(formatted_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00025d94",
   "metadata": {},
   "source": [
    "Haversine formula distance shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36c8ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.1.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.1.5)\n",
      "Requirement already satisfied: networkx in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.26.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "The shortest path from Istanbul to Colombo is: Jeddah, Riyadh, Abu Dhabi, Doha, Istanbul, Athens, Rome, Vienna, Prague\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Ritwik\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas openpyxl networkx numpy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Step 1: Load the data from the Excel files into pandas DataFrames.\n",
    "flight_connections = pd.read_excel('excel_tables.xlsx', sheet_name='Table 3')\n",
    "cities = pd.read_excel('excel_tables.xlsx', sheet_name='Table 4')\n",
    "\n",
    "# Step 2: Create a dictionary to easily access the coordinates of each city.\n",
    "city_coords = cities.set_index('City').to_dict('index')\n",
    "\n",
    "# Step 3: Define the Haversine distance function.\n",
    "def haversine_distance(city1, city2):\n",
    "    # Earth's radius in kilometers\n",
    "    R = 6371.0\n",
    "\n",
    "    # Get the coordinates of the two cities\n",
    "    lat1 = radians(city_coords[city1]['Latitude'])\n",
    "    lon1 = radians(city_coords[city1]['Longitude'])\n",
    "    lat2 = radians(city_coords[city2]['Latitude'])\n",
    "    lon2 = radians(city_coords[city2]['Longitude'])\n",
    "\n",
    "    # Calculate the differences in coordinates\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    # Apply the Haversine formula\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    # Calculate the distance\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Step 4: Calculate the Haversine distance for each flight connection.\n",
    "# We apply the haversine_distance function to each row of the flight_connections DataFrame\n",
    "# to create a new 'Haversine_Distance' column.\n",
    "flight_connections['Haversine_Distance'] = flight_connections.apply(\n",
    "    lambda row: haversine_distance(row['From'], row['To']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Step 5: Create a graph from the flight connections DataFrame.\n",
    "# The graph will use the 'From' and 'To' columns as the source and target of the edges.\n",
    "G = nx.from_pandas_edgelist(flight_connections, source='From', target='To', edge_attr='Haversine_Distance')\n",
    "\n",
    "# Step 6: Calculate the shortest path using the Haversine distance as the weight.\n",
    "# We specify 'Haversine_Distance' as the weight for the shortest path calculation.\n",
    "shortest_path = nx.shortest_path(G, source='Jeddah', target='Prague', weight='Haversine_Distance')\n",
    "\n",
    "# Step 7: Format and print the shortest path.\n",
    "# The result is a list of cities in the shortest path, which we join into a string.\n",
    "formatted_path = ', '.join(shortest_path)\n",
    "print(f\"The shortest path from Istanbul to Colombo is: {formatted_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99cb582",
   "metadata": {},
   "source": [
    "q3 Least unique subjects from CSV (1 mark)\n",
    "Download and unzip . It has 2 files:\n",
    "\n",
    "students.csv has 2 columns:\n",
    "studentId: A unique identifier for each student\n",
    "class: The class (including section) of the student\n",
    "subjects.csv has 2 columns:\n",
    "studentId: The identifier for each student\n",
    "subject: The name of the subject they have chosen\n",
    "What are the least number of subjects any class has taken up? List the 3 lowest count of subjects in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ec6f9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "31c4557e-5ae7-4b8e-87a4-a339d6098025",
       "rows": [
        [
         "299",
         "9N",
         "9"
        ],
        [
         "264",
         "8E",
         "28"
        ],
        [
         "265",
         "8F",
         "72"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>subject_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9N</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>8E</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>8F</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class  subject_count\n",
       "299    9N              9\n",
       "264    8E             28\n",
       "265    8F             72"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df = pd.read_csv('students.csv')\n",
    "subjects_df = pd.read_csv('subjects.csv')\n",
    "\n",
    "merged_df = pd.merge(students_df, subjects_df, on='studentId')\n",
    "# merged_df.head()\n",
    "\n",
    "subjects_per_class = merged_df.groupby('class')['subject'].nunique().reset_index()\n",
    "subjects_per_class.columns = ['class', 'subject_count']\n",
    "\n",
    "subjects_per_class.sort_values(by='subject_count', ascending=True).head(3)  # Get the 3 classes with the least number of subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caead9bb",
   "metadata": {},
   "source": [
    "q4  Extract tables from PDF (1 mark)\n",
    "Academic Performance Analysis for EduAnalytics\n",
    "EduAnalytics Corp. is a leading educational technology company that partners with schools and educational institutions to provide data-driven insights into student performance. By leveraging advanced analytics and reporting tools, EduAnalytics helps educators identify trends, improve teaching strategies, and enhance overall student outcomes. One of their key offerings is the Performance Insight Dashboard, which aggregates and analyzes student marks across various subjects and demographic groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "487e0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('merged_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dd4ba5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Answer",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c353547e-cba7-403e-9a89-0e81caf1d33d",
       "rows": [
        [
         "0",
         "32975"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Answer\n",
       "0   32975"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "def clean_data(data):\n",
    "    data['Group'] = (data.index // 30) + 1\n",
    "    # Filter students scoring 52+ in Economics and in groups 1-35\n",
    "    data = data[(data['Economics'] >= 52) & (data['Group'] >= 1) & (data['Group'] <= 35)]\n",
    "    # Calculate total Maths marks and wrap in DataFrame\n",
    "    total_maths_marks = data['Maths'].sum()\n",
    "    data = pd.DataFrame({'Answer': [total_maths_marks]})\n",
    "    return data\n",
    "\n",
    "data_clean = clean_data(data.copy())\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbcead",
   "metadata": {},
   "source": [
    "q5 DuckDB: Sales Over Time (1 mark)\n",
    "You are connected to a DuckDB database with a table called sales containing 10,000 rows of data with 3 columns.\n",
    "\n",
    "timestamp: When the sale occurred (for the week starting on 2024-01-01 UTC).\n",
    "category: Category of product sold (e.g. \"Electronics\", \"Clothing\", ...).\n",
    "amount: The sale value as a number (e.g. 12.34).\n",
    "Write the DuckDB SQL query to find the total sales amounts for each product category, pivoted by hour:\n",
    "\n",
    "Aggregate total sales amounts into hourly intervals (UTC) and pivot the data.\n",
    "Show total sales amount per category per hour (filling missing combinations with zeros), to the nearest integer.\n",
    "Order rows chronologically by hour and columns in any order.\n",
    "The result should look like this:\n",
    "What is the DuckDB SQL query to find the total sales amounts for each product category, pivoted by hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd90df",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    EXTRACT(HOUR FROM CAST(\"timestamp\" AS TIMESTAMP)) AS hour,\n",
    "    COALESCE(SUM(CASE WHEN category = 'Electronics' THEN amount END), 0) AS Electronics,\n",
    "    COALESCE(SUM(CASE WHEN category = 'Clothing' THEN amount END), 0) AS Clothing,\n",
    "    COALESCE(SUM(CASE WHEN category = 'Home Goods' THEN amount END), 0) AS \"Home Goods\"\n",
    "FROM sales\n",
    "GROUP BY hour\n",
    "ORDER BY hour;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049c4e98",
   "metadata": {},
   "source": [
    "q8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56d987a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pickup points in order:\n",
      "Request points from Table 2:\n",
      "1. Latitude: 50.9811, Longitude: -24.6377\n",
      "2. Latitude: 44.5508, Longitude: 143.3182\n",
      "3. Latitude: 41.4759, Longitude: 62.1823\n",
      "4. Latitude: 34.615, Longitude: 151.8026\n",
      "5. Latitude: 40.9594, Longitude: 156.3847\n",
      "\n",
      "Pickup Point 1: (50.9811, -24.6377)\n",
      "  Matches: 39, 52 -> Selected: 39\n",
      "\n",
      "Pickup Point 2: (44.5508, 143.3182)\n",
      "  No exact match -> Closest: 41\n",
      "\n",
      "Pickup Point 3: (41.4759, 62.1823)\n",
      "  Matches: 18 -> Selected: 18\n",
      "\n",
      "Pickup Point 4: (34.615, 151.8026)\n",
      "  No exact match -> Closest: 32\n",
      "\n",
      "Pickup Point 5: (40.9594, 156.3847)\n",
      "  Matches: 42 -> Selected: 42\n",
      "\n",
      "Final sequence (in order of pickup points): 39,41,18,32,42\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "# Read and process the data\n",
    "request_points = pd.read_excel('excel_tables.xlsx', sheet_name='Table 2')\n",
    "franchise_data = pd.read_excel('excel_tables.xlsx', sheet_name='Table 3')\n",
    "\n",
    "def parse_franchise_regions(franchise_data):\n",
    "    regions = []\n",
    "    for _, entry in franchise_data.iterrows():\n",
    "        franchisee_num = entry['Franchisee']\n",
    "        cities_str = entry['Cities [Latitude, Longitude]']\n",
    "        coord_pattern = r'\\[([+-]?\\d+(?:\\.\\d+)?),([+-]?\\d+(?:\\.\\d+)?)\\]'\n",
    "        coordinates = []\n",
    "        matches = re.findall(coord_pattern, cities_str)\n",
    "        for match in matches:\n",
    "            coordinates.append([float(match[0]), float(match[1])])\n",
    "        regions.append({\n",
    "            'franchisee': franchisee_num,\n",
    "            'polygon': coordinates\n",
    "        })\n",
    "    return regions\n",
    "\n",
    "def point_in_polygon(point, polygon):\n",
    "    x, y = point\n",
    "    inside = False\n",
    "    j = len(polygon) - 1\n",
    "    for i in range(len(polygon)):\n",
    "        xi, yi = polygon[i]\n",
    "        xj, yj = polygon[j]\n",
    "        if ((yi > y) != (yj > y)) and (x < (xj - xi) * (y - yi) / (yj - yi) + xi):\n",
    "            inside = not inside\n",
    "        j = i\n",
    "    return inside\n",
    "\n",
    "regions = parse_franchise_regions(franchise_data)\n",
    "\n",
    "# Process each pickup point IN ORDER\n",
    "print(\"Processing pickup points in order:\")\n",
    "print(\"Request points from Table 2:\")\n",
    "for index, row in request_points.iterrows():\n",
    "    print(f\"{index + 1}. Latitude: {row['Latitude']}, Longitude: {row['Longitude']}\")\n",
    "\n",
    "results = []\n",
    "for index, point in request_points.iterrows():\n",
    "    lat = point['Latitude']\n",
    "    lon = point['Longitude']\n",
    "    \n",
    "    print(f\"\\nPickup Point {index + 1}: ({lat}, {lon})\")\n",
    "    \n",
    "    # Find all matching franchisees\n",
    "    matching_franchisees = []\n",
    "    for region in regions:\n",
    "        if point_in_polygon([lat, lon], region['polygon']):\n",
    "            matching_franchisees.append(region['franchisee'])\n",
    "    \n",
    "    if len(matching_franchisees) > 0:\n",
    "        # If multiple matches, take the first (lowest number)\n",
    "        selected_franchisee = min(matching_franchisees)\n",
    "        print(f\"  Matches: {', '.join(map(str, matching_franchisees))} -> Selected: {selected_franchisee}\")\n",
    "        results.append(selected_franchisee)\n",
    "    else:\n",
    "        # Find closest franchisee\n",
    "        closest_franchisee = None\n",
    "        min_distance = float('inf')\n",
    "        \n",
    "        for region in regions:\n",
    "            lats = [p[0] for p in region['polygon']]\n",
    "            lons = [p[1] for p in region['polygon']]\n",
    "            centroid_lat = sum(lats) / len(lats)\n",
    "            centroid_lon = sum(lons) / len(lons)\n",
    "            \n",
    "            distance = math.sqrt((lat - centroid_lat)**2 + (lon - centroid_lon)**2)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_franchisee = region['franchisee']\n",
    "        \n",
    "        print(f\"  No exact match -> Closest: {closest_franchisee}\")\n",
    "        results.append(closest_franchisee)\n",
    "\n",
    "print(f\"\\nFinal sequence (in order of pickup points): {','.join(map(str, results))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b373035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: shapely in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from geopandas) (1.26.0)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from geopandas) (0.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from geopandas) (2.1.1)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from geopandas) (3.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=2.0.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=2.0.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=2.0.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyogrio>=0.7.2->geopandas) (2025.7.14)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ritwik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\Ritwik\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'request_points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point, Polygon\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Prepare pickup points as GeoDataFrame\u001b[39;00m\n\u001b[0;32m      7\u001b[0m pickup_gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mrequest_points\u001b[49m,\n\u001b[0;32m      9\u001b[0m     geometry\u001b[38;5;241m=\u001b[39m[Point(lon, lat) \u001b[38;5;28;01mfor\u001b[39;00m lat, lon \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(request_points[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], request_points[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m])],\n\u001b[0;32m     10\u001b[0m     crs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Prepare franchisee polygons as GeoDataFrame\u001b[39;00m\n\u001b[0;32m     14\u001b[0m franchisee_polys \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'request_points' is not defined"
     ]
    }
   ],
   "source": [
    "%pip install geopandas shapely\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# Prepare pickup points as GeoDataFrame\n",
    "pickup_gdf = gpd.GeoDataFrame(\n",
    "    request_points,\n",
    "    geometry=[Point(lon, lat) for lat, lon in zip(request_points['Latitude'], request_points['Longitude'])],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Prepare franchisee polygons as GeoDataFrame\n",
    "franchisee_polys = []\n",
    "franchisee_ids = []\n",
    "for region in regions:\n",
    "    # Polygon expects (lon, lat) tuples\n",
    "    poly = Polygon([(lon, lat) for lat, lon in region['polygon']])\n",
    "    franchisee_polys.append(poly)\n",
    "    franchisee_ids.append(region['franchisee'])\n",
    "\n",
    "franchisee_gdf = gpd.GeoDataFrame(\n",
    "    {'franchisee': franchisee_ids, 'geometry': franchisee_polys},\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Spatial join: find which polygon contains each pickup point\n",
    "joined = gpd.sjoin(pickup_gdf, franchisee_gdf, predicate='within', how='left')\n",
    "\n",
    "# Output franchisee assignment in order\n",
    "assigned = joined['franchisee'].fillna(\"None\").astype(str).tolist()\n",
    "print(\",\".join(assigned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fda8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def point_in_polygon(lat, lon, polygon):\n",
    "    # Check if a point is inside a polygon using the ray-casting algorithm\n",
    "    n = len(polygon)\n",
    "    inside = False\n",
    "    p1x, p1y = polygon[0]\n",
    "    for i in range(n + 1):\n",
    "        p2x, p2y = polygon[i % n]\n",
    "        if lon > min(p1x, p2x):\n",
    "            if lon <= max(p1x, p2x):\n",
    "                if lat <= max(p1y, p2y):\n",
    "                    if p1y != p2y:\n",
    "                        xinters = (lon - p1x) * (p2y - p1y) / (p2x - p1x) + p1y\n",
    "                    if p1y == p2y or lat <= xinters:\n",
    "                        inside = not inside\n",
    "        p1x, p1y = p2x, p2y\n",
    "    return inside\n",
    "\n",
    "def find_polygons_for_coordinates(coordinates, regions):\n",
    "    results = []\n",
    "    for lat, lon in coordinates:\n",
    "        matching_polygons = []\n",
    "        for region_name, polygon in regions.items():\n",
    "            if point_in_polygon(lat, lon, polygon):\n",
    "                matching_polygons.append(region_name)\n",
    "        results.append(matching_polygons)\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
